from app.ml.forecaster import forecast_expenses
from app.models import Transaction
from app import openai_client
import logging

logger = logging.getLogger(__name__)

def chat_with_assistant(client_id, messages):
    last_user_message = [m['message'] for m in messages if m['role'] == 'user'][-1].lower()

    # Check if user probably wants forecast
    if "expenses" in last_user_message or "forecast" in last_user_message:
        # Fetch transactions
        txns = Transaction.query.filter_by(client_id=client_id).all()
        txn_data = [{"date": txn.date, "amount": float(txn.amount)} for txn in txns]

        if not txn_data:
            forecast_result = "I don't have enough data to forecast your expenses yet."
        else:
            prediction = forecast_expenses(txn_data)
            if prediction:
                forecast_result = f"My forecast: Estimated expenses on {prediction['ds'].date()} are approximately {prediction['yhat']:.2f} EUR."
            else:
                forecast_result = "Sorry, I couldn't generate a forecast at this time."

        # Add logging
        logger.info(f"forecast_result: {forecast_result}")

        # Let GPT-4 wrap this forecast naturally into its reply
        system_prompt = (
            "You are a friendly financial assistant. "
            "If the user's message seems playful or they might enjoy humor, add a short funny comment, trivia, or roast about spending habits in English. "
            "Otherwise, reply professionally. "
            "The following forecast was generated by your backend: "
            f"'{forecast_result}'. "
            "Please include this forecast in your answer so the user always sees it."
        )

        completion = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                *[
                    {"role": m["role"], "content": m["message"]}
                    for m in messages
                ]
            ]
        )

        return completion.choices[0].message.content

    # Fallback: other small talk, GPT-4 decides tone
    system_prompt = (
        "You are a friendly financial assistant. "
        "If the user's message seems playful or they might enjoy humor, add a short funny comment, trivia or roast about spending habits in English. "
        "Otherwise, reply professionally."
    )

    completion = openai_client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            *[
                {"role": m["role"], "content": m["message"]}
                for m in messages
            ]
        ]
    )

    return completion.choices[0].message.content
